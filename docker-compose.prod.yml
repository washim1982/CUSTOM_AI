services:
  backend:
    build: ./backend
    image: washim1982/custom_ai-backend:v1.4
    volumes:
      - ./backend/data:/code/data
      - ./backend/loras:/code/loras
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    environment:
      - OLLAMA_HOST=http://ollama:11434

  # --- frontend service REMOVED ---

  ollama:
    image: ollama/ollama
    ports:
      - "11434:11434" # Keep if needed, otherwise remove if only accessed via backend
    volumes:
      - ollama_data:/root/.ollama
      - ./backend/loras:/loras
      - ./ollama_entrypoint.sh:/ollama_entrypoint.sh
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    entrypoint: ["/ollama_entrypoint.sh"]

  nginx:
    # --- Build directly using the frontend's Dockerfile ---
    build:
      context: .
      dockerfile: frontend/Dockerfile
    # --- REMOVE image: nginx:1.25-alpine ---
    image: washim1982/custom_ai-nginx:v1.4
    ports:
      - "80:80"
      - "443:443"
    volumes:
      # Keep NGINX config mount
      - ./nginx/nginx.prod.conf:/etc/nginx/conf.d/default.conf
      # Keep certs mounts
      - letsencrypt_certs:/etc/letsencrypt
      - certbot_www:/var/www/certbot
      - ./options-ssl-nginx.conf:/etc/letsencrypt/options-ssl-nginx.conf:ro
      # --- REMOVE ./frontend/build mount ---
    depends_on:
      - backend # Only depends on backend now
    restart: unless-stopped

  certbot:
    image: certbot/certbot
    volumes:
      - letsencrypt_certs:/etc/letsencrypt
      - certbot_www:/var/www/certbot
    entrypoint: "/bin/sh -c 'trap exit TERM; while :; do certbot renew; sleep 12h & wait $${!}; done;'"

volumes:
  ollama_data:
  letsencrypt_certs:
  certbot_www: